{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Scale Time Series Modelling with Fugue\n",
    "\n",
    "This tutorial will be about scaling time series modelling to Spark, Dask, and Ray. When dealing with large scale data, there are two approaches users can take. The first one is they can train a model for the whole dataset. The approach is training a model for each inidividual timeseries. \n",
    "\n",
    "Timeseries data is very friednly to distributed computing because we normally have hundreds or thousands of relatively independent data points. We can pre-process and model each one independently. This set-up allows choosing the best model for each timeseries. If we have 100 time series, it's very possible that 50 will be better modelled with ARIMA and another 50 will be better modelled with ETS.\n",
    "\n",
    "Related article: [Distributed Forecast of 1M Time Series in under 15 mins with Spark, Nixtla, and Fugue](https://towardsdatascience.com/distributed-forecast-of-1m-time-series-in-under-15-minutes-with-spark-nixtla-and-fugue-e9892da6fd5c)\n",
    "\n",
    "The main tools used in this tutorial are:\n",
    "\n",
    "[Nixtla](https://github.com/Nixtla) - The Nixtla project is focused lightning fast state-of-the-art timeseries modelling. The project has a few libraries\n",
    "* [statsforecast](https://github.com/Nixtla/statsforecast) - focused on statistic and econometric models such as ARIMA, ETS \n",
    "\n",
    "[Fugue](https://github.com/fugue-project/fugue/) - an abstraction layer for Spark, Dask, and Ray. Fugue ports code written for local execution to distributed execution.\n",
    "\n",
    "[Spark](https://github.com/apache/spark) on [Databricks](https://www.databricks.com/) - a distributed computing engine built on top of the JVM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals \n",
    "\n",
    "1. Learn how to deal with large scale data effectively\n",
    "2. Demostrate a distributed model training available for every logical group of data\n",
    "3. Show some SOTA timeseries forecasting work\n",
    "\n",
    "Not covered:\n",
    "1. Time series models for specific use cases (sparse, 0's, irregular)\n",
    "2. Time series basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tooling\n",
    "\n",
    "![architecture](../img/architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Look at Nixtla\n",
    "\n",
    "We're going to take a quick look at Nixtla to understand the form data needs to be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsforecast.utils import generate_series\n",
    "\n",
    "series = generate_series(n_series=2, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(16,4))\n",
    "series = series.reset_index()\n",
    "for unique_id in range(2):\n",
    "    plt.figure()\n",
    "    _temp = series.loc[series['unique_id'] == unique_id]\n",
    "    sns.lineplot(x=_temp['ds'], y=_temp['y'], ax=axs[unique_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to reset the index for distributed backends.\n",
    "\n",
    "ETS is doing 15 models and AutoARIMA is doing 100-something models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import AutoARIMA, ETS\n",
    "from statsforecast.core import StatsForecast\n",
    "\n",
    "sf = StatsForecast(df=series,\n",
    "                   models=[AutoARIMA(), ETS()], \n",
    "                   freq='D', \n",
    "                   n_jobs=-1)\n",
    "\n",
    "forecasts = sf.forecast(7)\n",
    "forecasts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(16,4))\n",
    "combined = pd.concat(\n",
    "    [forecasts.reset_index().melt(id_vars=[\"unique_id\",\"ds\"]).rename(columns={\"variable\":\"model\", \"value\": \"y\"}),\n",
    "    series.assign(model=\"truth\")]\n",
    "    , axis=0, ignore_index=True)\n",
    "\n",
    "for unique_id in range(2):\n",
    "    plt.figure()\n",
    "    _temp = combined.loc[combined['unique_id'] == unique_id]\n",
    "    sns.lineplot(x=_temp['ds'], y=_temp['y'], hue=_temp['model'], ax=axs[unique_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit-Predict Interface\n",
    "\n",
    "With classical machine learning models, it's a very common approach to save the model weights with something like pickle to be loaded during prediction time. This is less common for timeseries modelling because the focus is on a lightweight train-predict when predictions are needed. This is what the `forecast()` method does.\n",
    "\n",
    "Still, Nixtla has a `scikit-learn` type `fit-predict()` interface. Below is what it would look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StatsForecast(df=series,\n",
    "                      models=[AutoARIMA(), ETS()], \n",
    "                      freq='D', \n",
    "                      n_jobs=-1)\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict function will just take in a horizon. \n",
    "\n",
    "There is an overhead to test multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(h=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the fitting, the `StatsForecast` object will contain the fitted models for each unique id. Note that you can't train on timeseries A, and predict on a different timeseries B (yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fitted_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fitted_[0][0].model_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FugueBackend to Run on Spark, Dask, and Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_series(n_series=50, seed=1).reset_index()\n",
    "series['unique_id'] = series['unique_id'].astype(int)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from statsforecast.distributed.utils import forecast\n",
    "from statsforecast.distributed.fugue import FugueBackend\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "backend = FugueBackend(spark)\n",
    "result = forecast(series, \n",
    "                  models=[AutoARIMA()], \n",
    "                  freq=\"D\", \n",
    "                  h=7, \n",
    "                  parallel=backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In this section, we took an initial look how to use Nixtla's Statsforecat. In the next section, we'll begin applying it to a problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9fcd6e71927f6b3e5f4fa4280b4e8e6a66aa8d4365bb61cf7ef4017620fc09b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
